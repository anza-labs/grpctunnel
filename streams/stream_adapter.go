package streams

import (
	"context"
	"fmt"
	"io"
	"sync"
	"sync/atomic"

	"google.golang.org/grpc"
)

// CorruptResponseStreamError is an error that occurs when a correlated stream
// adapter receives a message that cannot be correlated to a pending request.
type CorruptResponseStreamError struct {
	resp  any
	key   any
	count uint64
}

// Error implements the error interface
func (e CorruptResponseStreamError) Error() string {
	return fmt.Sprintf("Corrupt response stream: received message #%d for unexpected key %v: %v", e.count, e.key, e.resp)
}

// response is a tuple that can hold either a response message or an error
type response[T any] struct {
	resp T
	err  error
}

type void struct{}

// NewStreamAdapter returns a stream adapter that correlates responses with
// their corresponding requests via the given key extractor functions. If either
// function is nil, both must be nil (in which case the extracted key is the nil
// interface, meaning everything must be correlated via FIFO order).
//
// A request message is supplied to requestKeyExtractor to determine the key.
// When a response message is received, the given responseKeyExtractor is
// consulted. The resulting response key is expected to match the key of a
// pending request. If a message is received that does not correspond to any
// pending request, the stream is closed and all pending operations fail with
// a CorruptResponseStreamError.
//
// If there are multiple pending requests for a particular key, they are
// serviced in FIFO order. So if two requests map to the same key, the first
// matching response is assumed to correspond to the first such request, and
// so on.
//
// The given responseFactory is used to create new instances into which response
// data is unmarshaled. If it is nil, the given stream must have a Recv method
// that accepts no arguments and returns two: a response message and an error.
// The return type will be examined (via reflection) and values of the right
// type will be created via reflection. Stream types generated by protoc for use
// with normal gRPC streaming stubs will have such a method and thus can be used
// so that calling code need not explicitly supply a factory.
//
// This function is used on the client side of the stream -- the side that will
// send requests and then expects responses in reply. (This does not necessarily
// have to be a gRPC client though, as a stream could allow servers to initiate
// requests this way). For the server side of the stream, see HandleServerStream.
func NewStreamAdapter[Req any, Resp any](stream Stream[Req, Resp]) StreamAdapter[Req, Resp] {
	return NewStreamAdapterWithCorrelationKey[Req, Resp, void](
		stream,
		func(Req) void { return void{} },
		func(Resp) void { return void{} },
	)
}

func NewStreamAdapterWithCorrelationKey[Req any, Resp any, K comparable](
	stream Stream[Req, Resp],
	requestKeyExtractor func(Req) K,
	responseKeyExtractor func(Resp) K,
) StreamAdapter[Req, Resp] {
	if requestKeyExtractor == nil {
		panic("cannot correlate keys with nil requestKeyExtractor")
	}
	if responseKeyExtractor == nil {
		panic("cannot correlate keys with nil responseKeyExtractor")
	}

	ctx, cancel := context.WithCancel(stream.Context())
	return &streamAdapter[Req, Resp, K]{
		ctx:                  ctx,
		cancel:               cancel,
		stream:               stream,
		requestKeyExtractor:  requestKeyExtractor,
		responseKeyExtractor: responseKeyExtractor,
		pending:              map[K][]chan<- response[Resp]{},
	}
}

// Stream is the common interface shared by both grpc.ServerStream and
// grpc.ClientStream. This package allows full-duplex bidi streams to be used in
// either direction -- so servers can initiate operations by sending a message
// to the client, in addition to the more typical direction where clients
// initiate operations.
type Stream[SendType any, ReceiveType any] interface {
	Context() context.Context
	Send(SendType) error
	Recv() (ReceiveType, error)
}

type StreamAdapter[Req any, Resp any] interface {
	Context() context.Context
	Call(context.Context, Req) (Resp, error)
}

// streamAdapter wraps a gRPC stream and implements a simple request-response
// mechanism on top of it.
type streamAdapter[Req any, Resp any, K comparable] struct {
	ctx                  context.Context
	cancel               context.CancelFunc
	stream               Stream[Req, Resp]
	responseFactory      func() Resp
	requestKeyExtractor  func(Req) K
	responseKeyExtractor func(Resp) K

	messageCount uint64

	mu      sync.Mutex
	failure error
	pending map[K][]chan<- response[Resp]
}

// Call performs a single request-response round trip. It sends the given
// request on the stream and waits for a corresponding response, which is
// recorded in the given response message. It returns a non-nil error in
// the event of a failure.
//
// If the given context contains request metadata, they are ignored. Also,
// as observed in the signature, gRPC call options are not supported. The
// context is only used to allow the call to return early in the event of
// context completion (in which case the return values will be the context
// error). If the context times out or is cancelled, nothing happens in the
// underlying stream, and any response message that eventually arrives will
// effectively be ignored.
func (a *streamAdapter[Req, Resp, K]) Call(ctx context.Context, req Req) (Resp, error) {
	// optimistically add response acceptor to pending set
	var key K
	if a.requestKeyExtractor != nil {
		key = a.requestKeyExtractor(req)
	}
	ch := make(chan response[Resp], 1)

	var zeroResp Resp
	err, startRecvLoop := a.addPending(key, ch)
	if err != nil {
		return zeroResp, err
	}

	if err := a.stream.Send(req); err != nil {
		// remove from pending set
		if !a.removePending(key, ch) {
			// it must have been concurrently removed by recvLoop on stream failure
			select {
			case r := <-ch:
				return r.resp, r.err
			default:
				// TODO: shouldn't ever happen... panic?
			}
		}
		return zeroResp, err
	}

	// make sure we have something accepting response messages
	if startRecvLoop {
		go a.recvLoop()
	}

	// wait for response
	select {
	case r := <-ch:
		return r.resp, r.err
	case <-ctx.Done():
		return zeroResp, ctx.Err()
	}
}

func (a *streamAdapter[Req, Resp, K]) addPending(key K, ch chan<- response[Resp]) (error, bool) {
	a.mu.Lock()
	defer a.mu.Unlock()

	if a.failure != nil {
		return a.failure, false
	}
	shouldStartRecvLoop := len(a.pending) == 0
	a.pending[key] = append(a.pending[key], ch)
	return nil, shouldStartRecvLoop
}

func (a *streamAdapter[Req, Resp, K]) removePending(key K, ch chan<- response[Resp]) bool {
	a.mu.Lock()
	defer a.mu.Unlock()

	resps := a.pending[key]
	for i, v := range resps {
		if v == ch {
			// remove element from slice
			copy(resps[i:], resps[i+1:])
			a.pending[key] = resps[:len(resps)-1]
			return true
		}
	}

	return false
}

// Context returns the context associate with this stream.
func (a *streamAdapter[Req, Resp, K]) Context() context.Context {
	return a.ctx
}

func (a *streamAdapter[Req, Resp, K]) recvLoop() {
	for {
		m, err := a.stream.Recv()
		if err != nil {
			// fail all pending operations and bail
			a.abortPending(err)
			return
		}
		c := atomic.AddUint64(&a.messageCount, 1)
		var key K
		if a.responseKeyExtractor != nil {
			key = a.responseKeyExtractor(m)
		}
		done := a.replyToPending(m, key, c)
		if done {
			return
		}
	}
}

func (a *streamAdapter[Req, Resp, K]) replyToPending(resp Resp, key K, count uint64) bool {
	a.mu.Lock()
	defer a.mu.Unlock()

	noMorePending := false

	var ch chan<- response[Resp]
	if chans, ok := a.pending[key]; ok {
		ch = chans[0]
		if len(chans) > 1 {
			a.pending[key] = chans[1:]
		} else {
			delete(a.pending, key)
			if len(a.pending) == 0 {
				noMorePending = true
			}
		}
		ch <- response[Resp]{resp, nil}
		close(ch)
	} else {
		// no pending request that corresponds to the received response?
		if cs, ok := a.stream.(grpc.ClientStream); ok {
			_ = cs.CloseSend()
		}
		a.cancel()

		a.failure = CorruptResponseStreamError{resp, key, count}
		a.abortPendingLocked(a.failure)
		noMorePending = true
	}

	return noMorePending
}

func (a *streamAdapter[Req, Resp, K]) abortPending(err error) {
	a.mu.Lock()
	defer a.mu.Unlock()

	a.abortPendingLocked(err)
}

func (a *streamAdapter[Req, Resp, K]) abortPendingLocked(err error) {
	var zeroResp Resp
	for _, chans := range a.pending {
		for _, ch := range chans {
			ch <- response[Resp]{zeroResp, err}
			close(ch)
		}
	}
	a.pending = map[K][]chan<- response[Resp]{}
}

// HandleServerStream reads request messages from the given stream, dispatching
// them to the given serveFunc. The serveFunc must be a function that either
// accepts one argument and returns one value or accepts two arguments, the
// first of which must be a context.Context, and returns one value.
//
// The given requestKeyExtractor is used to determine a key. All requests for
// the same key are processed in FIFO order. If no such extractor is given, then
// the nil interface is the assumed key, eliminating parallelism. If an
// extractor is given, requests for different keys will be dispatched to
// serveFunc concurrently, from different goroutines. It is serveFunc's job to
// mark its return values with the same key, so that the client can correctly
// correlate responses with outstanding RPC requests.
//
// The given requestFactory is used to create request instances, into which
// stream messages are unmarshaled. If nil is supplied, a factory will be
// created by querying the given stream for a method named "Recv" (via
// reflection). If it has such a method, it should take no arguments and return
// a value and an error. The type of that first return value will be used to
// reflectively construct request instances.
//
// This function returns an error if a call to stream.RecvMsg(), to query for
// the next request, returns an error.
//
// This function is used on the server side of the stream -- the side that will
// receive requests and then send responses in reply. (This does not necessarily
// have to be a gRPC server though, as a stream could allow clients to accept
// and process requests this way). For the client side of the stream, see
// NewStreamAdapter.
func HandleServerStream[Req any, Resp any](stream Stream[Resp, Req], handler func(context.Context, Req) Resp) error {
	return HandleServerStreamWithCorrelationKey[Req, Resp, void](stream, handler, func(Req) void { return void{} })
}

func HandleServerStreamWithCorrelationKey[Req any, Resp any, K comparable](
	stream Stream[Resp, Req],
	handler func(context.Context, Req) Resp,
	requestKeyExtractor func(Req) K,
) error {
	w := &workers[Req, Resp, K]{
		stream:              stream,
		action:              handler,
		requestKeyExtractor: requestKeyExtractor,
	}
	w.ctx, w.cancel = context.WithCancel(stream.Context())
	defer w.await()

	for {
		m, err := stream.Recv()
		if err != nil {
			if err == io.EOF {
				return nil
			}
			return err
		}
		w.enqueue(m)
	}
}

type workers[Req any, Resp any, K comparable] struct {
	stream              Stream[Resp, Req]
	action              func(context.Context, Req) Resp
	requestKeyExtractor func(Req) K
	ctx                 context.Context
	cancel              context.CancelFunc
	wg                  sync.WaitGroup

	mu      sync.Mutex
	workers map[K]worker[Req]
}

type worker[T any] struct {
	input chan<- *workRequest[T]
}

type workRequest[T any] struct {
	req  T
	skip int32 // used as atomic boolean; set to 1 to retract request
}

func (w *workers[Req, Resp, K]) await() {
	w.wg.Wait()
}

func (w *workers[Req, Resp, K]) enqueue(req Req) {
	var key K
	if w.requestKeyExtractor != nil {
		key = w.requestKeyExtractor(req)
	}

	for {
		w.mu.Lock()
		wk, ok := w.workers[key]
		if !ok {
			// don't release lock; we need to create new worker below
			break
		}

		// unlock before trying to send worker a request
		w.mu.Unlock()

		wr := &workRequest[Req]{req: req}
		select {
		case wk.input <- wr:
			// worker accepted request? double-check that
			// worker didn't asynchronously exit
			w.mu.Lock()
			wk2, active := w.workers[key]
			w.mu.Unlock()
			wkIsActive := active && wk2 == wk
			if !wkIsActive && atomic.CompareAndSwapInt32(&wr.skip, 0, 1) {
				// worker exited and did not process this item,
				// so we need to get a new worker...
				continue
			}
			return
		case <-w.ctx.Done():
			// stream shutting down, bail
			return
		}
	}

	defer w.mu.Unlock()

	input := make(chan *workRequest[Req], 16)
	wk := worker[Req]{input: input}
	w.workers[key] = wk

	// TODO: limit parallelism?

	w.wg.Add(1)
	go func() {
		defer w.wg.Done()
		w.processRequests(key, input)
	}()
}

func (w *workers[Req, Resp, K]) processRequests(key K, input <-chan *workRequest[Req]) {
	for {
		var req *workRequest[Req]
		select {
		case req = <-input:
			if !w.processOneRequest(req) {
				// stream is in bad state
				return
			}

		case <-w.ctx.Done():
			// operation cancelled
			return

		default:
			// No tasks available; try to quit. Make sure we
			// aren't racing with a goroutine adding something
			// to the input channel.
			w.mu.Lock()
			noExit := false
			select {
			case req = <-input:
				noExit = true
			default:
				delete(w.workers, key)
			}
			w.mu.Unlock()

			if !noExit {
				return
			}

			// otherwise, we found an item we need to process so can't exit yet
			if !w.processOneRequest(req) {
				// stream is in bad state
				return
			}
		}
	}
}

func (w *workers[Req, Resp, K]) processOneRequest(req *workRequest[Req]) bool {
	if !atomic.CompareAndSwapInt32(&req.skip, 0, -1) {
		// request was already marked, so skip
		return true
	}
	resp := w.action(w.ctx, req.req)
	if err := w.stream.Send(resp); err != nil {
		w.cancel()
		// stream is in bad state
		return false
	}
	return true
}
